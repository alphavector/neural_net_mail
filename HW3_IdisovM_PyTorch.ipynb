{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW3_IdisovM_PyTorch.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"W0R3_CMFqLvH","colab_type":"text"},"cell_type":"markdown","source":["Задание: обучить модель на MNIST до 97% используя PyTorch"]},{"metadata":{"id":"PtyxbDMn34en","colab_type":"code","colab":{}},"cell_type":"code","source":["# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rbo_eV-33-L-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"679e1493-4339-4402-cff8-61ea64fc0679","executionInfo":{"status":"ok","timestamp":1541539580374,"user_tz":-180,"elapsed":1513,"user":{"displayName":"AFYDOZ","photoUrl":"","userId":"05462912882712587906"}}},"cell_type":"code","source":["import torch\n","torch.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.4.1'"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"T_6OvFpn3_y8","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import time\n","import torch.nn\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from torch.autograd import Variable\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3FEKwM1W4A0k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":302},"outputId":"b566f5d9-4e43-4da9-d7d8-acb80c3289cb","executionInfo":{"status":"ok","timestamp":1541539583993,"user_tz":-180,"elapsed":1949,"user":{"displayName":"AFYDOZ","photoUrl":"","userId":"05462912882712587906"}}},"cell_type":"code","source":["import torchvision\n","\n","train_mnist = torchvision.datasets.MNIST('data_mnist/train', train=True, transform=None,  download=True)\n","test_mnist = torchvision.datasets.MNIST('data_mnist/train', train=False, transform=None, download=True)\n","\n","print(train_mnist[0])\n","pixels = np.asarray(train_mnist[0][0])\n","\n","\n","plt.imshow(pixels)\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(<PIL.Image.Image image mode=L size=28x28 at 0x7FEA124BF8D0>, tensor(5))\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fea123d1dd8>"]},"metadata":{"tags":[]},"execution_count":4},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<matplotlib.figure.Figure at 0x7fea124bf978>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"CEDpGEm44GIs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":302},"outputId":"92eae309-e4a8-40d7-b553-04e501dc277d","executionInfo":{"status":"ok","timestamp":1541539585320,"user_tz":-180,"elapsed":1266,"user":{"displayName":"AFYDOZ","photoUrl":"","userId":"05462912882712587906"}}},"cell_type":"code","source":["import torchvision.transforms as transforms\n","import torchvision.utils\n","import torch.nn as nn\n","\n","\n","train_mnist = torchvision.datasets.MNIST('data_mnist/train', train=True, transform=transforms.Compose([transforms.ToTensor()]),  download=True)\n","test_mnist = torchvision.datasets.MNIST('data_mnist/train', train=False, transform=transforms.Compose([transforms.ToTensor()]), download=True)\n","\n","print(train_mnist[0][0].shape)\n","plt.imshow(train_mnist[0][0][0])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["torch.Size([1, 28, 28])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fea0faf30f0>"]},"metadata":{"tags":[]},"execution_count":5},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<matplotlib.figure.Figure at 0x7fea57b01ef0>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"MED0XLVJ4H6M","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 50\n","\n","train_loader = torch.utils.data.DataLoader(\n","                 dataset=train_mnist,\n","                 batch_size=batch_size,\n","                 shuffle=True)\n","test_loader = torch.utils.data.DataLoader(\n","                dataset=test_mnist,\n","                batch_size=batch_size,\n","shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JaIyc9M74PK0","colab_type":"code","colab":{}},"cell_type":"code","source":["class NetworkForMNIST(nn.Module):\n","  def __init__(self,zero_prop):\n","    super(NetworkForMNIST, self).__init__() \n","    self.fc1 = nn.Linear(28*28,10)\n","    self.fc1_sigmoid = nn.Sigmoid()\n","    self.dropout = nn.Dropout(p=zero_prop)\n","    \n","  def forward(self,x):\n","    y = self.dropout(self.fc1_sigmoid(self.fc1(x)))\n","    return y\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y2u1BuRs4uFA","colab_type":"code","colab":{}},"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1, 320)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dbliyeOd4ROE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":4399},"outputId":"de6dd15c-0d16-4484-a509-183c51070eca","executionInfo":{"status":"ok","timestamp":1541540609324,"user_tz":-180,"elapsed":255561,"user":{"displayName":"AFYDOZ","photoUrl":"","userId":"05462912882712587906"}}},"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda else 'cpu')\n","EPOCH = 20\n","#model = NetworkForMNIST(0.2)\n","model = Net()\n","#Переводит модель в режим обучения\n","model.train()\n","model.to(device)\n","\n","\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(),lr=1e-5)\n","\n","def accuracy(output,labels):\n","  predictions = torch.argmax(output,dim=1)\n","  correct = (predictions == labels).sum().cpu().numpy()\n","  return correct / len(labels)\n","\n","\n","\n","start_time = time.time()\n","for epoch in range(EPOCH):\n","  for itr,data in enumerate(train_loader):\n","    imgs = data[0].to(device)\n","    labels = data[1].to(device)\n","\n","    #imgs = imgs.view(-1,28*28)\n","    \n","    y_pred = model.forward(imgs)\n","\n","    optimizer.zero_grad()\n","    \n","    loss = loss_func(y_pred,labels)\n","    if itr%100 == 0:\n","      print('Iteration {}, train accuracy {:.2f}, loss {:.4f}'.format(itr+epoch*len(train_loader),accuracy(y_pred,labels),loss))\n","      \n","    loss.backward()\n","    \n","    optimizer.step()\n","    \n","print('Total time {:.4f} seconds'.format(time.time() - start_time))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Iteration 0, train accuracy 0.06, loss 2.3201\n","Iteration 100, train accuracy 0.10, loss 2.3103\n","Iteration 200, train accuracy 0.10, loss 2.2869\n","Iteration 300, train accuracy 0.06, loss 2.3077\n","Iteration 400, train accuracy 0.12, loss 2.2858\n","Iteration 500, train accuracy 0.08, loss 2.3030\n","Iteration 600, train accuracy 0.08, loss 2.3028\n","Iteration 700, train accuracy 0.18, loss 2.2687\n","Iteration 800, train accuracy 0.16, loss 2.2768\n","Iteration 900, train accuracy 0.12, loss 2.2815\n","Iteration 1000, train accuracy 0.24, loss 2.2518\n","Iteration 1100, train accuracy 0.10, loss 2.2732\n","Iteration 1200, train accuracy 0.22, loss 2.2595\n","Iteration 1300, train accuracy 0.12, loss 2.2765\n","Iteration 1400, train accuracy 0.30, loss 2.2438\n","Iteration 1500, train accuracy 0.22, loss 2.2396\n","Iteration 1600, train accuracy 0.30, loss 2.2082\n","Iteration 1700, train accuracy 0.40, loss 2.1480\n","Iteration 1800, train accuracy 0.20, loss 2.2413\n","Iteration 1900, train accuracy 0.36, loss 2.1608\n","Iteration 2000, train accuracy 0.40, loss 2.1229\n","Iteration 2100, train accuracy 0.34, loss 2.1382\n","Iteration 2200, train accuracy 0.22, loss 2.1549\n","Iteration 2300, train accuracy 0.28, loss 2.1567\n","Iteration 2400, train accuracy 0.32, loss 2.1093\n","Iteration 2500, train accuracy 0.36, loss 2.0120\n","Iteration 2600, train accuracy 0.42, loss 1.9792\n","Iteration 2700, train accuracy 0.48, loss 1.8702\n","Iteration 2800, train accuracy 0.48, loss 1.8982\n","Iteration 2900, train accuracy 0.36, loss 1.9550\n","Iteration 3000, train accuracy 0.34, loss 1.9965\n","Iteration 3100, train accuracy 0.52, loss 1.7410\n","Iteration 3200, train accuracy 0.46, loss 1.8577\n","Iteration 3300, train accuracy 0.54, loss 1.8458\n","Iteration 3400, train accuracy 0.54, loss 1.6807\n","Iteration 3500, train accuracy 0.44, loss 1.7905\n","Iteration 3600, train accuracy 0.42, loss 1.7611\n","Iteration 3700, train accuracy 0.36, loss 1.8434\n","Iteration 3800, train accuracy 0.36, loss 1.8006\n","Iteration 3900, train accuracy 0.34, loss 1.8534\n","Iteration 4000, train accuracy 0.46, loss 1.7348\n","Iteration 4100, train accuracy 0.38, loss 1.5768\n","Iteration 4200, train accuracy 0.46, loss 1.5751\n","Iteration 4300, train accuracy 0.56, loss 1.4435\n","Iteration 4400, train accuracy 0.42, loss 1.6576\n","Iteration 4500, train accuracy 0.52, loss 1.4073\n","Iteration 4600, train accuracy 0.52, loss 1.5656\n","Iteration 4700, train accuracy 0.54, loss 1.5628\n","Iteration 4800, train accuracy 0.58, loss 1.3987\n","Iteration 4900, train accuracy 0.62, loss 1.4170\n","Iteration 5000, train accuracy 0.56, loss 1.3507\n","Iteration 5100, train accuracy 0.48, loss 1.4862\n","Iteration 5200, train accuracy 0.62, loss 1.3252\n","Iteration 5300, train accuracy 0.68, loss 1.2758\n","Iteration 5400, train accuracy 0.58, loss 1.4265\n","Iteration 5500, train accuracy 0.54, loss 1.4500\n","Iteration 5600, train accuracy 0.58, loss 1.2823\n","Iteration 5700, train accuracy 0.58, loss 1.4374\n","Iteration 5800, train accuracy 0.60, loss 1.2087\n","Iteration 5900, train accuracy 0.58, loss 1.2271\n","Iteration 6000, train accuracy 0.60, loss 1.2454\n","Iteration 6100, train accuracy 0.46, loss 1.4809\n","Iteration 6200, train accuracy 0.56, loss 1.4203\n","Iteration 6300, train accuracy 0.70, loss 1.0742\n","Iteration 6400, train accuracy 0.60, loss 1.2056\n","Iteration 6500, train accuracy 0.66, loss 1.1268\n","Iteration 6600, train accuracy 0.56, loss 1.2085\n","Iteration 6700, train accuracy 0.58, loss 1.1903\n","Iteration 6800, train accuracy 0.58, loss 1.2551\n","Iteration 6900, train accuracy 0.56, loss 1.1754\n","Iteration 7000, train accuracy 0.62, loss 1.0274\n","Iteration 7100, train accuracy 0.68, loss 1.1425\n","Iteration 7200, train accuracy 0.68, loss 1.0103\n","Iteration 7300, train accuracy 0.64, loss 1.2304\n","Iteration 7400, train accuracy 0.58, loss 1.0767\n","Iteration 7500, train accuracy 0.68, loss 1.0718\n","Iteration 7600, train accuracy 0.74, loss 0.9408\n","Iteration 7700, train accuracy 0.68, loss 1.2080\n","Iteration 7800, train accuracy 0.74, loss 0.9191\n","Iteration 7900, train accuracy 0.64, loss 1.0704\n","Iteration 8000, train accuracy 0.80, loss 0.8539\n","Iteration 8100, train accuracy 0.82, loss 0.8460\n","Iteration 8200, train accuracy 0.72, loss 0.9676\n","Iteration 8300, train accuracy 0.68, loss 1.0663\n","Iteration 8400, train accuracy 0.66, loss 0.9576\n","Iteration 8500, train accuracy 0.76, loss 0.8247\n","Iteration 8600, train accuracy 0.62, loss 1.0351\n","Iteration 8700, train accuracy 0.56, loss 1.2122\n","Iteration 8800, train accuracy 0.76, loss 0.8004\n","Iteration 8900, train accuracy 0.78, loss 0.7101\n","Iteration 9000, train accuracy 0.68, loss 0.9902\n","Iteration 9100, train accuracy 0.78, loss 0.9365\n","Iteration 9200, train accuracy 0.72, loss 0.7963\n","Iteration 9300, train accuracy 0.66, loss 0.9665\n","Iteration 9400, train accuracy 0.72, loss 0.8356\n","Iteration 9500, train accuracy 0.62, loss 0.9324\n","Iteration 9600, train accuracy 0.72, loss 1.0759\n","Iteration 9700, train accuracy 0.62, loss 1.1302\n","Iteration 9800, train accuracy 0.70, loss 1.1114\n","Iteration 9900, train accuracy 0.78, loss 0.8232\n","Iteration 10000, train accuracy 0.70, loss 1.0680\n","Iteration 10100, train accuracy 0.72, loss 0.9568\n","Iteration 10200, train accuracy 0.72, loss 0.9387\n","Iteration 10300, train accuracy 0.70, loss 0.8017\n","Iteration 10400, train accuracy 0.68, loss 0.9920\n","Iteration 10500, train accuracy 0.68, loss 0.8702\n","Iteration 10600, train accuracy 0.72, loss 0.8864\n","Iteration 10700, train accuracy 0.68, loss 0.7981\n","Iteration 10800, train accuracy 0.76, loss 0.7783\n","Iteration 10900, train accuracy 0.82, loss 0.6709\n","Iteration 11000, train accuracy 0.68, loss 0.8495\n","Iteration 11100, train accuracy 0.54, loss 1.0099\n","Iteration 11200, train accuracy 0.80, loss 0.6185\n","Iteration 11300, train accuracy 0.72, loss 0.8795\n","Iteration 11400, train accuracy 0.78, loss 0.8587\n","Iteration 11500, train accuracy 0.80, loss 0.5696\n","Iteration 11600, train accuracy 0.76, loss 0.7950\n","Iteration 11700, train accuracy 0.72, loss 0.8863\n","Iteration 11800, train accuracy 0.70, loss 0.7909\n","Iteration 11900, train accuracy 0.76, loss 0.8519\n","Iteration 12000, train accuracy 0.76, loss 0.6392\n","Iteration 12100, train accuracy 0.66, loss 1.0686\n","Iteration 12200, train accuracy 0.80, loss 0.7180\n","Iteration 12300, train accuracy 0.72, loss 1.0822\n","Iteration 12400, train accuracy 0.70, loss 0.8856\n","Iteration 12500, train accuracy 0.76, loss 0.8995\n","Iteration 12600, train accuracy 0.84, loss 0.5169\n","Iteration 12700, train accuracy 0.72, loss 0.8846\n","Iteration 12800, train accuracy 0.68, loss 1.0569\n","Iteration 12900, train accuracy 0.78, loss 0.6861\n","Iteration 13000, train accuracy 0.74, loss 0.6924\n","Iteration 13100, train accuracy 0.80, loss 0.6932\n","Iteration 13200, train accuracy 0.78, loss 0.6696\n","Iteration 13300, train accuracy 0.72, loss 0.7974\n","Iteration 13400, train accuracy 0.82, loss 0.7769\n","Iteration 13500, train accuracy 0.72, loss 0.9022\n","Iteration 13600, train accuracy 0.68, loss 0.8061\n","Iteration 13700, train accuracy 0.70, loss 0.9374\n","Iteration 13800, train accuracy 0.62, loss 0.9262\n","Iteration 13900, train accuracy 0.64, loss 0.8864\n","Iteration 14000, train accuracy 0.76, loss 0.6213\n","Iteration 14100, train accuracy 0.74, loss 0.8059\n","Iteration 14200, train accuracy 0.72, loss 0.6936\n","Iteration 14300, train accuracy 0.72, loss 0.7176\n","Iteration 14400, train accuracy 0.74, loss 0.7000\n","Iteration 14500, train accuracy 0.76, loss 0.8927\n","Iteration 14600, train accuracy 0.70, loss 1.0177\n","Iteration 14700, train accuracy 0.80, loss 0.6110\n","Iteration 14800, train accuracy 0.88, loss 0.6063\n","Iteration 14900, train accuracy 0.72, loss 0.8666\n","Iteration 15000, train accuracy 0.84, loss 0.5533\n","Iteration 15100, train accuracy 0.86, loss 0.5104\n","Iteration 15200, train accuracy 0.80, loss 0.7157\n","Iteration 15300, train accuracy 0.78, loss 0.9347\n","Iteration 15400, train accuracy 0.84, loss 0.7311\n","Iteration 15500, train accuracy 0.74, loss 0.8031\n","Iteration 15600, train accuracy 0.78, loss 0.5309\n","Iteration 15700, train accuracy 0.72, loss 0.7761\n","Iteration 15800, train accuracy 0.78, loss 0.6357\n","Iteration 15900, train accuracy 0.90, loss 0.4905\n","Iteration 16000, train accuracy 0.82, loss 0.4935\n","Iteration 16100, train accuracy 0.84, loss 0.4953\n","Iteration 16200, train accuracy 0.86, loss 0.4665\n","Iteration 16300, train accuracy 0.82, loss 0.7069\n","Iteration 16400, train accuracy 0.86, loss 0.4689\n","Iteration 16500, train accuracy 0.78, loss 0.6220\n","Iteration 16600, train accuracy 0.74, loss 0.7440\n","Iteration 16700, train accuracy 0.84, loss 0.4748\n","Iteration 16800, train accuracy 0.82, loss 0.6431\n","Iteration 16900, train accuracy 0.74, loss 0.8020\n","Iteration 17000, train accuracy 0.80, loss 0.6910\n","Iteration 17100, train accuracy 0.78, loss 0.7483\n","Iteration 17200, train accuracy 0.82, loss 0.5503\n","Iteration 17300, train accuracy 0.84, loss 0.5261\n","Iteration 17400, train accuracy 0.82, loss 0.6889\n","Iteration 17500, train accuracy 0.80, loss 0.7737\n","Iteration 17600, train accuracy 0.84, loss 0.5997\n","Iteration 17700, train accuracy 0.70, loss 0.8875\n","Iteration 17800, train accuracy 0.74, loss 0.7663\n","Iteration 17900, train accuracy 0.88, loss 0.6757\n","Iteration 18000, train accuracy 0.76, loss 0.6803\n","Iteration 18100, train accuracy 0.78, loss 0.6168\n","Iteration 18200, train accuracy 0.88, loss 0.5424\n","Iteration 18300, train accuracy 0.86, loss 0.5546\n","Iteration 18400, train accuracy 0.72, loss 0.8245\n","Iteration 18500, train accuracy 0.68, loss 0.8231\n","Iteration 18600, train accuracy 0.74, loss 0.7029\n","Iteration 18700, train accuracy 0.84, loss 0.6145\n","Iteration 18800, train accuracy 0.84, loss 0.5551\n","Iteration 18900, train accuracy 0.88, loss 0.3556\n","Iteration 19000, train accuracy 0.76, loss 0.6458\n","Iteration 19100, train accuracy 0.74, loss 0.8899\n","Iteration 19200, train accuracy 0.74, loss 0.6510\n","Iteration 19300, train accuracy 0.74, loss 0.7976\n","Iteration 19400, train accuracy 0.80, loss 0.5946\n","Iteration 19500, train accuracy 0.78, loss 0.5851\n","Iteration 19600, train accuracy 0.76, loss 0.8417\n","Iteration 19700, train accuracy 0.78, loss 0.7147\n","Iteration 19800, train accuracy 0.88, loss 0.5532\n","Iteration 19900, train accuracy 0.86, loss 0.6036\n","Iteration 20000, train accuracy 0.82, loss 0.6538\n","Iteration 20100, train accuracy 0.80, loss 0.6396\n","Iteration 20200, train accuracy 0.92, loss 0.3963\n","Iteration 20300, train accuracy 0.82, loss 0.6025\n","Iteration 20400, train accuracy 0.86, loss 0.4512\n","Iteration 20500, train accuracy 0.80, loss 0.5640\n","Iteration 20600, train accuracy 0.90, loss 0.4465\n","Iteration 20700, train accuracy 0.78, loss 0.9517\n","Iteration 20800, train accuracy 0.80, loss 0.6543\n","Iteration 20900, train accuracy 0.90, loss 0.4335\n","Iteration 21000, train accuracy 0.84, loss 0.4099\n","Iteration 21100, train accuracy 0.78, loss 0.7395\n","Iteration 21200, train accuracy 0.78, loss 0.4849\n","Iteration 21300, train accuracy 0.76, loss 0.7964\n","Iteration 21400, train accuracy 0.84, loss 0.6826\n","Iteration 21500, train accuracy 0.80, loss 0.6523\n","Iteration 21600, train accuracy 0.80, loss 0.6099\n","Iteration 21700, train accuracy 0.84, loss 0.7706\n","Iteration 21800, train accuracy 0.88, loss 0.7507\n","Iteration 21900, train accuracy 0.74, loss 0.5968\n","Iteration 22000, train accuracy 0.88, loss 0.3914\n","Iteration 22100, train accuracy 0.76, loss 0.5017\n","Iteration 22200, train accuracy 0.80, loss 0.6311\n","Iteration 22300, train accuracy 0.66, loss 1.0712\n","Iteration 22400, train accuracy 0.88, loss 0.4215\n","Iteration 22500, train accuracy 0.84, loss 0.5994\n","Iteration 22600, train accuracy 0.84, loss 0.5360\n","Iteration 22700, train accuracy 0.84, loss 0.5233\n","Iteration 22800, train accuracy 0.82, loss 0.6183\n","Iteration 22900, train accuracy 0.86, loss 0.4384\n","Iteration 23000, train accuracy 0.86, loss 0.4806\n","Iteration 23100, train accuracy 0.82, loss 0.4169\n","Iteration 23200, train accuracy 0.78, loss 0.7643\n","Iteration 23300, train accuracy 0.86, loss 0.5274\n","Iteration 23400, train accuracy 0.96, loss 0.4034\n","Iteration 23500, train accuracy 0.82, loss 0.5849\n","Iteration 23600, train accuracy 0.90, loss 0.4383\n","Iteration 23700, train accuracy 0.78, loss 0.6218\n","Iteration 23800, train accuracy 0.76, loss 0.5787\n","Iteration 23900, train accuracy 0.70, loss 0.6707\n","Total time 254.7622 seconds\n"],"name":"stdout"}]},{"metadata":{"id":"Dh-r4GxA4iOt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"850a2639-a4a7-4020-8014-2eae15ef0ebd","executionInfo":{"status":"ok","timestamp":1541540274307,"user_tz":-180,"elapsed":2095,"user":{"displayName":"AFYDOZ","photoUrl":"","userId":"05462912882712587906"}}},"cell_type":"code","source":["#Переводит модель в режим инференса\n","model.eval()\n","\n","with torch.no_grad():\n","  accuracy_list = []\n","  for itr,data in enumerate(test_loader):\n","    imgs = data[0].to(device)\n","    labels = data[1].to(device)\n","\n","    #imgs = imgs.view(-1,28*28)\n","    \n","    y_pred = model.forward(imgs)\n","    accuracy_list.append(accuracy(y_pred,labels))\n","\n","print('Test accuracy - {:.2f}'.format(np.sum(accuracy_list)/len(accuracy_list)))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Test accuracy - 0.97\n"],"name":"stdout"}]},{"metadata":{"id":"miKvCR277QNs","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}